{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse of Grenoble Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of the PLU of Grenoble. First step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "from google.genai import types\n",
    "\n",
    "from src.api.gemini_thinking import gemini_api\n",
    "from src.config import (\n",
    "    INTERIM_DATA_DIR,\n",
    "    PROJ_ROOT,\n",
    "    RAW_DATA_DIR,\n",
    ")\n",
    "\n",
    "# Load pompts and tree data\n",
    "with open(PROJ_ROOT / \"config/prompts.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    prompts = json.load(f)\n",
    "\n",
    "with open(PROJ_ROOT / \"config/plu_tree.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
    "    tree_grenoble = yaml.safe_load(f)[\"Grenoble\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_zone_pages(ocr_json: dict, prompt: str) -> dict:\n",
    "    \"\"\"\n",
    "    Récupère les pages du document et les affiche dans des parties séparées.\n",
    "\n",
    "    Args:\n",
    "        ocr_json: (dict) La réponse JSON brute de l'OCR.\n",
    "\n",
    "    Returns:\n",
    "        La réponse brute complète du modèle sous format dict:\n",
    "        {\n",
    "        \"Zone1\": [liste des numéros de pages avec informations sur la zone Zone1],\n",
    "        \"Zone2\": [liste des numéros de pages avec informations sur la zone Zone2],\n",
    "        \"Zone3\": [liste des numéros de pages avec informations sur la zone Zone3],\n",
    "        \"...\": [...],\n",
    "        }\n",
    "    \"\"\"\n",
    "    instruction: str = types.Part.from_text(text=prompt)\n",
    "    parts = [instruction]\n",
    "    for i, page in enumerate(ocr_json.get(\"pages\")):\n",
    "        parts.append(\n",
    "            types.Part.from_text(\n",
    "                text=json.dumps(\n",
    "                    f\"PAGE {i + 1} : \" + page[\"markdown\"], ensure_ascii=False\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    response = gemini_api(parts=parts)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = RAW_DATA_DIR\n",
    "int_dir = INTERIM_DATA_DIR\n",
    "folder = \"Grenoble\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Data\n",
    "\n",
    "**Résultats**\n",
    "- documents_generaux: `{nom_document: contenu_json}`\n",
    "    \n",
    "    Un dictionnaire où les clés sont les noms des documents généraux et les valeurs sont\n",
    "    leur contenu au format JSON.\n",
    "\n",
    "- data_par_zone: `{type_zone: {nom_zone: [pages_texte]}}`\n",
    "    \n",
    "    Un dictionnaire où les clés sont les noms des zones et les valeurs sont des sous-dictionnaires\n",
    "    où chaque clé représente une zone spécifique *(ex: 'Zone_A', 'Zone_AL')* avec comme valeurs\n",
    "    les listes des pages extraites du document original correspondant à cette zone.\n",
    "\n",
    "- data_zone: `{type_zone: {nom_zone: contenu_json}}`\n",
    "    \n",
    "    Un dictionnaire imbriqué où le premier niveau représente les types de zones\n",
    "    *(ex: 'Zone Urbaine', 'Zone Agricole')* et le second niveau contient les données\n",
    "    spécifiques à chaque zone où les clés sont les noms des zones *(ex: 'Zone_A')*\n",
    "    et les valeurs sont leur contenu au format JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Documents Généraux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generaux = {}\n",
    "for doc in tree_grenoble[\"documents_generaux\"]:\n",
    "    path_doc = Path(raw_dir / Path(\"Grenoble\") / doc).with_suffix(\".json\")\n",
    "    with open(path_doc, \"r\", encoding=\"utf-8\") as f:\n",
    "        data_generaux[doc] = json.load(f)\n",
    "\n",
    "print(data_generaux.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Documents Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zone_unique = {}\n",
    "for zone_a, zones in tree_grenoble[\"documents_par_zone\"].items():\n",
    "    data_zone_unique[zone_a] = {}\n",
    "    for zone in zones:\n",
    "        path_zone = Path(raw_dir / Path(\"Grenoble\") / zone_a / zone).with_suffix(\n",
    "            \".json\"\n",
    "        )\n",
    "        with open(path_zone, \"r\", encoding=\"utf-8\") as f:\n",
    "            data_zone_unique[zone_a][zone] = json.load(f)\n",
    "\n",
    "print(data_zone_unique.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Documents Par Zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On récupère d'abord les pages de la zone.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_dict = {}\n",
    "[\"Zone à Urbaniser\", \"Zone Agricoles\", \"Zone Dédiée\", \"Zone Urbaines\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_a = \"Zone Urbaines\"\n",
    "\n",
    "par_zone = \"Par \" + zone_a\n",
    "path_par_zone = Path(raw_dir / Path(\"Grenoble\") / par_zone).with_suffix(\".json\")\n",
    "with open(path_par_zone, \"r\", encoding=\"utf-8\") as f:\n",
    "    data_zone = json.load(f)\n",
    "response = retrieve_zone_pages(ocr_json=data_zone, prompt=prompts[\"retrieve_page_zone\"])\n",
    "pages_dict[zone_a] = json.loads(response.text.replace(\"```\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On isole les pages à partir de là.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_par_zone = {}\n",
    "for zone_a in tree_grenoble[\"documents_par_zone\"]:\n",
    "    par_zone = \"Par \" + zone_a\n",
    "    path_par_zone = Path(raw_dir / Path(\"Grenoble\") / par_zone).with_suffix(\".json\")\n",
    "    with open(path_par_zone, \"r\", encoding=\"utf-8\") as f:\n",
    "        data_zone = json.load(f)\n",
    "\n",
    "    data_par_zone[zone_a] = {}\n",
    "    for zone, pages in pages_dict[zone_a].items():\n",
    "        data_par_zone[zone_a][zone] = [data_zone[\"pages\"][i] for i in pages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formattage vant de sauvegarder\n",
    "\n",
    "Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"ZoneUA1\": \"Zone_UA1\",\n",
    "    \"ZoneUA2\": \"Zone_UA2\",\n",
    "    \"ZoneUA3\": \"Zone_UA3\",\n",
    "    # ...,\n",
    "    \"informations_generales\": \"informations_generales\",\n",
    "}\n",
    "\n",
    "mon_dict = dict()\n",
    "\n",
    "# Ou pour modifier le dictionnaire existant\n",
    "for old_key, new_key in mapping.items():\n",
    "    if old_key in mon_dict:\n",
    "        mon_dict[new_key] = mon_dict.pop(old_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SAVE THE RESULTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/data_par_zone.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data_par_zone, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open(\"output/data_zone_unique.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data_zone_unique, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open(\"output/data_generaux.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data_generaux, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_grenoble(\n",
    "    zone: str,\n",
    "    prompt: str,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Récupère le prompt pour la ville de Grenoble.\n",
    "\n",
    "    Args:\n",
    "        data_general: (dict) Les données générales de la ville de Grenoble.\n",
    "        data_par_zone: (dict) Les données par zone de la ville de Grenoble.\n",
    "        data_zone: (dict) Les données de zone de la ville de Grenoble.\n",
    "        type_zone: (str) Le type de zone à analyser.\n",
    "        zone: (str) La zone à analyser.\n",
    "        prompt: (str) Le prompt de base.\n",
    "\n",
    "    Returns:\n",
    "        str: Le prompt pour la ville de Grenoble.\n",
    "    \"\"\"\n",
    "    return prompt.format(\n",
    "        ZONE_CADASTRALE_CIBLE=zone,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dir: Path = int_dir / folder\n",
    "folder_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# On ne garde que les données textuelles des Dispositions Générales\n",
    "temp_data = data_generaux[\"Dispositions Générales\"][\"pages\"]\n",
    "temp_data_generaux = [\n",
    "    f\"page {temp_data[i]['index'] + 1}: \" + temp_data[i][\"markdown\"]\n",
    "    for i in range(len(temp_data))\n",
    "]\n",
    "\n",
    "for par_zone in tree_grenoble[\"documents_par_zone\"]:\n",
    "    par_zone_dir: Path = folder_dir / par_zone\n",
    "    par_zone_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for zone in tree_grenoble[\"documents_par_zone\"][par_zone]:\n",
    "        # Ce sont les données textuelles des PLU par type de zone filtrées\n",
    "        temp_data = data_par_zone[par_zone][zone]\n",
    "        temp_data_par_zone = [\n",
    "            f\"page {temp_data[i]['index'] + 1}: \" + temp_data[i][\"markdown\"]\n",
    "            for i in range(len(temp_data))\n",
    "        ]\n",
    "\n",
    "        # Ce sont les données textuelles uniquement des PLU de chaque Zone\n",
    "        temp_data = data_zone_unique[par_zone][zone][\"pages\"]\n",
    "        temp_data_zone_unique = [\n",
    "            f\"page {temp_data[i]['index'] + 1}: \" + temp_data[i][\"markdown\"]\n",
    "            for i in range(len(temp_data))\n",
    "        ]\n",
    "        document_content = {\n",
    "            f\"PLU de la {zone.replace('_', ' ')}\": temp_data_zone_unique,\n",
    "            f\"Réglement des {par_zone}\": temp_data_par_zone,\n",
    "            \"Dispositions Générales\": temp_data_generaux,\n",
    "        }\n",
    "        save_folder = Path(f\"output/{par_zone}\")\n",
    "        save_folder.mkdir(exist_ok=True, parents=True)\n",
    "        save_path = save_folder / Path(zone).with_suffix(\".json\")\n",
    "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(document_content, fp=f, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case : Zone_AU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il me faut le `prompt` : \"data/interim/Grenoble/prompts/Zone à Urbaniser/Zone_AU.txt\"\n",
    "\n",
    "Et les images qui vont avec, à convertir en `types.format_text` : \n",
    "- data/raw/markdown/Grenoble/Zone à Urbaniser/Zone_AU/images\n",
    "- data/raw/markdown/Grenoble/Par Zone à Urbaniser/images\n",
    "- data/raw/markdown/Grenoble/Dispositions Générales/images\n",
    "\n",
    "En triant les images qui sont utiles et à insérer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "with open(\"output/Zone Urbaines/Zone_UC2.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data_zone_uc2 = json.load(f)\n",
    "\n",
    "image_folder_dg = (\n",
    "    \"/mnt/mydisk/Projects/plu/data/raw/markdown/Grenoble/Dispositions Générales/images\"\n",
    ")\n",
    "image_folder_zone_uc = (\n",
    "    \"/mnt/mydisk/Projects/plu/data/raw/markdown/Grenoble/Zone Urbaine/Zone_UC2/images\"\n",
    ")\n",
    "image_folder_par_zone = (\n",
    "    \"/mnt/mydisk/Projects/plu/data/raw/markdown/Grenoble/Par Zone Urbaines/images\"\n",
    ")\n",
    "\n",
    "pattern = r\"!\\[(?P<alt>[^\\]]*)\\]\\((?P<filename>[^)]+)\\)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "\n",
    "def text_to_part_with_images(text: str, pattern: str, image_folder: Path) -> list:\n",
    "    \"\"\"\n",
    "    Scinde une chaîne de texte selon un pattern donné.\n",
    "    Retourne une liste contenant les parties de texte et les éléments correspondant au pattern.\n",
    "\n",
    "    Args:\n",
    "        text (str): Le texte à analyser.\n",
    "        pattern (str): Le motif regex pour identifier les images.\n",
    "        image_folder (Path): Le dossier contenant les images.\n",
    "\n",
    "    Returns:\n",
    "        list: Une liste d'objets Part contenant le texte et les images.\n",
    "    \"\"\"\n",
    "    # Compile le motif regex pour une meilleure performance\n",
    "    regex = re.compile(pattern)\n",
    "\n",
    "    # Trouve tous les matches du pattern dans le texte\n",
    "    matches = list(regex.finditer(text))\n",
    "\n",
    "    # S'il n'y a pas de match, retourne le texte original\n",
    "    if not matches:\n",
    "        return [types.Part.from_text(text=text)]\n",
    "\n",
    "    # Liste pour stocker les segments de texte et les éléments correspondant au pattern\n",
    "    result = []\n",
    "\n",
    "    # Position de départ pour le split\n",
    "    last_end = 0\n",
    "\n",
    "    # Parcourt tous les matches\n",
    "    for match in matches:\n",
    "        # Ajoute le texte avant le match (s'il y en a)\n",
    "        if match.start() > last_end:\n",
    "            text_segment = text[last_end : match.start()]\n",
    "            result.append(types.Part.from_text(text=text_segment))\n",
    "\n",
    "        # Récupère le chemin de l'image correspondant au match\n",
    "        img_filename = match.group(\"filename\")\n",
    "        img_path = os.path.join(image_folder, img_filename)\n",
    "        try:\n",
    "            result.append(Image.open(img_path))\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Image not found: {img_path}\")\n",
    "\n",
    "        # Met à jour la position de fin\n",
    "        last_end = match.end()\n",
    "\n",
    "    # Ajoute le reste du texte après le dernier match\n",
    "    if last_end < len(text):\n",
    "        result.append(types.Part.from_text(text=text[last_end:]))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pompts and tree data\n",
    "with open(PROJ_ROOT / \"config/prompts.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    prompts = json.load(f)\n",
    "\n",
    "prompt_data = []\n",
    "\n",
    "for page_text in data_zone_uc2[\"PLU de la Zone UC2\"]:\n",
    "    prompt_data += text_to_part_with_images(\n",
    "        text=page_text,\n",
    "        pattern=pattern,\n",
    "        image_folder=image_folder_zone_uc,\n",
    "    )\n",
    "\n",
    "for page_text in data_zone_uc2[\"Réglement des Zone Urbaines\"]:\n",
    "    prompt_data += text_to_part_with_images(\n",
    "        text=page_text,\n",
    "        pattern=pattern,\n",
    "        image_folder=image_folder_par_zone,\n",
    "    )\n",
    "\n",
    "for page_text in data_zone_uc2[\"Dispositions Générales\"]:\n",
    "    prompt_data += text_to_part_with_images(\n",
    "        text=page_text,\n",
    "        pattern=pattern,\n",
    "        image_folder=image_folder_dg,\n",
    "    )\n",
    "\n",
    "prompt_template = get_prompt_grenoble(\n",
    "    document_content=\"DOCUMENT_CONTENT\",\n",
    "    zone=\"Zone UC2\",\n",
    "    prompt=prompts[\"prompt_grenoble\"],\n",
    ").split(\"DOCUMENT_CONTENT\")\n",
    "\n",
    "prompt_final = (\n",
    "    [types.Part.from_text(text=prompt_template[0])]\n",
    "    + prompt_data\n",
    "    + [types.Part.from_text(text=prompt_template[1])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(\n",
    "    api_key=os.environ.get(\"GOOGLE_AI_API_KEY\"),\n",
    ")\n",
    "model = \"gemini-2.5-pro-exp-03-25\"\n",
    "generate_content_config = types.GenerateContentConfig(\n",
    "    response_mime_type=\"text/plain\",\n",
    ")\n",
    "response = client.models.generate_content(\n",
    "    model=model,\n",
    "    contents=prompt_final,\n",
    "    config=generate_content_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, List, Optional\n",
    "\n",
    "\n",
    "def save_json_data(data: Dict[str, Any], file_path: Path) -> None:\n",
    "    \"\"\"\n",
    "    Sauvegarde des données au format JSON.\n",
    "\n",
    "    Args:\n",
    "        data (Dict[str, Any]): Données à sauvegarder\n",
    "        file_path (Path): Chemin où sauvegarder le fichier\n",
    "    \"\"\"\n",
    "    # Créer le répertoire parent si nécessaire\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json_data(\n",
    "    data=response.to_json_dict(), file_path=Path(\"output/gemini_response/Zone_UC2.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.platypus import (\n",
    "    SimpleDocTemplate,\n",
    "    Paragraph,\n",
    "    Spacer,\n",
    "    ListItem,\n",
    "    ListFlowable,\n",
    "    Table,\n",
    "    TableStyle,\n",
    ")\n",
    "from reportlab.lib.units import mm\n",
    "\n",
    "\n",
    "def extract_text_from_json(json_file_path):\n",
    "    \"\"\"\n",
    "    Extrait le contenu textuel de la réponse du modèle à partir du fichier JSON.\n",
    "\n",
    "    Args:\n",
    "        json_file_path (str): Chemin vers le fichier JSON\n",
    "\n",
    "    Returns:\n",
    "        str: Le contenu textuel extrait\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ouvrir et charger le fichier JSON\n",
    "        with open(json_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        # Naviguer dans la structure JSON pour obtenir le texte\n",
    "        # Vérifier la structure pour s'assurer que tous les champs existent\n",
    "        if (\n",
    "            \"candidates\" in data\n",
    "            and len(data[\"candidates\"]) > 0\n",
    "            and \"content\" in data[\"candidates\"][0]\n",
    "            and \"parts\" in data[\"candidates\"][0][\"content\"]\n",
    "            and len(data[\"candidates\"][0][\"content\"][\"parts\"]) > 0\n",
    "            and \"text\" in data[\"candidates\"][0][\"content\"][\"parts\"][0]\n",
    "        ):\n",
    "            # Extraire le texte\n",
    "            text_content = data[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "\n",
    "            # Extraire le contenu Markdown en supprimant les balises de code\n",
    "            if text_content.startswith(\"```\") and \"```\" in text_content:\n",
    "                # Utiliser une expression régulière pour extraire le contenu entre les balises de code\n",
    "                match = re.search(r\"```(?:text|markdown)?\\n([\\s\\S]*?)```\", text_content)\n",
    "                if match:\n",
    "                    return match.group(1)\n",
    "\n",
    "            return text_content\n",
    "        else:\n",
    "            return \"Structure JSON invalide. Impossible de trouver le contenu textuel.\"\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        return \"Le fichier n'est pas un JSON valide.\"\n",
    "    except Exception as e:\n",
    "        return f\"Une erreur est survenue: {str(e)}\"\n",
    "\n",
    "\n",
    "def save_as_markdown(json_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    Extrait le contenu du JSON et le sauvegarde en format Markdown.\n",
    "\n",
    "    Args:\n",
    "        json_file_path (str): Chemin vers le fichier JSON\n",
    "        output_file_path (str): Chemin où sauvegarder le fichier Markdown\n",
    "\n",
    "    Returns:\n",
    "        bool: True si l'opération a réussi, False sinon\n",
    "    \"\"\"\n",
    "    try:\n",
    "        content = extract_text_from_json(json_file_path)\n",
    "\n",
    "        # Sauvegarder dans un fichier Markdown\n",
    "        with open(output_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(content)\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la sauvegarde en Markdown: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def format_markdown_text(text):\n",
    "    \"\"\"\n",
    "    Convertit certaines balises Markdown en balises HTML pour ReportLab.\n",
    "\n",
    "    Args:\n",
    "        text (str): Texte avec formatage Markdown\n",
    "\n",
    "    Returns:\n",
    "        str: Texte avec balises HTML\n",
    "    \"\"\"\n",
    "    # Convertir le texte en gras (**texte**) en balises HTML <b>\n",
    "    text = re.sub(r\"\\*\\*(.*?)\\*\\*\", r\"<b>\\1</b>\", text)\n",
    "\n",
    "    # Convertir le texte en italique (*texte*) en balises HTML <i>\n",
    "    text = re.sub(r\"(?<!\\*)\\*(?!\\*)(.*?)(?<!\\*)\\*(?!\\*)\", r\"<i>\\1</i>\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def save_as_pdf(json_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    Extrait le contenu du JSON et le sauvegarde en format PDF en utilisant ReportLab.\n",
    "\n",
    "    Args:\n",
    "        json_file_path (str): Chemin vers le fichier JSON\n",
    "        output_file_path (str): Chemin où sauvegarder le fichier PDF\n",
    "\n",
    "    Returns:\n",
    "        bool: True si l'opération a réussi, False sinon\n",
    "    \"\"\"\n",
    "    try:\n",
    "        content = extract_text_from_json(json_file_path)\n",
    "\n",
    "        # Créer un nouveau document PDF\n",
    "        doc = SimpleDocTemplate(\n",
    "            output_file_path,\n",
    "            pagesize=A4,\n",
    "            rightMargin=20 * mm,\n",
    "            leftMargin=20 * mm,\n",
    "            topMargin=20 * mm,\n",
    "            bottomMargin=20 * mm,\n",
    "        )\n",
    "\n",
    "        # Définir les styles\n",
    "        styles = getSampleStyleSheet()\n",
    "\n",
    "        # Modifier les styles existants au lieu d'en ajouter de nouveaux\n",
    "        styles[\"Heading1\"].fontSize = 16\n",
    "        styles[\"Heading1\"].spaceAfter = 10\n",
    "        styles[\"Heading1\"].spaceBefore = 20\n",
    "        styles[\"Heading1\"].textColor = colors.darkblue\n",
    "\n",
    "        styles[\"Heading2\"].fontSize = 14\n",
    "        styles[\"Heading2\"].spaceAfter = 8\n",
    "        styles[\"Heading2\"].spaceBefore = 16\n",
    "        styles[\"Heading2\"].textColor = colors.darkblue\n",
    "\n",
    "        styles[\"Heading3\"].fontSize = 12\n",
    "        styles[\"Heading3\"].spaceAfter = 6\n",
    "        styles[\"Heading3\"].spaceBefore = 12\n",
    "        styles[\"Heading3\"].textColor = colors.darkblue\n",
    "\n",
    "        # Vérifier si Heading4 existe et le modifier ou le créer\n",
    "        if \"Heading4\" in styles:\n",
    "            styles[\"Heading4\"].fontSize = 11\n",
    "            styles[\"Heading4\"].spaceAfter = 4\n",
    "            styles[\"Heading4\"].spaceBefore = 10\n",
    "            styles[\"Heading4\"].textColor = colors.darkblue\n",
    "        else:\n",
    "            styles.add(\n",
    "                ParagraphStyle(\n",
    "                    name=\"Heading4\",\n",
    "                    parent=styles[\"Normal\"],\n",
    "                    fontSize=11,\n",
    "                    spaceAfter=4,\n",
    "                    spaceBefore=10,\n",
    "                    textColor=colors.darkblue,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Vérifier si Heading5 existe et le modifier ou le créer\n",
    "        if \"Heading5\" in styles:\n",
    "            styles[\"Heading5\"].fontSize = 10\n",
    "            styles[\"Heading5\"].spaceAfter = 4\n",
    "            styles[\"Heading5\"].spaceBefore = 8\n",
    "            styles[\"Heading5\"].textColor = colors.darkblue\n",
    "        else:\n",
    "            styles.add(\n",
    "                ParagraphStyle(\n",
    "                    name=\"Heading5\",\n",
    "                    parent=styles[\"Normal\"],\n",
    "                    fontSize=10,\n",
    "                    spaceAfter=4,\n",
    "                    spaceBefore=8,\n",
    "                    textColor=colors.darkblue,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Modifier le style Normal\n",
    "        styles[\"Normal\"].fontSize = 10\n",
    "        styles[\"Normal\"].spaceAfter = 6\n",
    "\n",
    "        # Vérifier si ListItem existe et le modifier ou le créer\n",
    "        if \"ListItem\" in styles:\n",
    "            styles[\"ListItem\"].leftIndent = 20\n",
    "            styles[\"ListItem\"].spaceAfter = 3\n",
    "        else:\n",
    "            styles.add(\n",
    "                ParagraphStyle(\n",
    "                    name=\"ListItem\",\n",
    "                    parent=styles[\"Normal\"],\n",
    "                    leftIndent=20,\n",
    "                    spaceAfter=3,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Créer le style Source (il n'existe pas par défaut)\n",
    "        styles.add(\n",
    "            ParagraphStyle(\n",
    "                name=\"Source\",\n",
    "                parent=styles[\"Normal\"],\n",
    "                fontSize=8,\n",
    "                textColor=colors.grey,\n",
    "                spaceAfter=6,\n",
    "                leftIndent=20,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Préparer la liste des éléments à ajouter au PDF\n",
    "        elements = []\n",
    "\n",
    "        # Traiter le contenu ligne par ligne\n",
    "        lines = content.split(\"\\n\")\n",
    "        in_list = False\n",
    "        list_items = []\n",
    "        current_list_type = None  # 'bullet' ou 'numbered'\n",
    "\n",
    "        for line in lines:\n",
    "            # Traiter les en-têtes\n",
    "            if line.startswith(\"# \"):\n",
    "                if in_list:\n",
    "                    # Ajouter la liste précédente si on entre dans un nouvel élément\n",
    "                    if list_items:\n",
    "                        elements.append(\n",
    "                            ListFlowable(\n",
    "                                list_items, bulletType=current_list_type or \"bullet\"\n",
    "                            )\n",
    "                        )\n",
    "                        list_items = []\n",
    "                        in_list = False\n",
    "                        current_list_type = None\n",
    "                elements.append(\n",
    "                    Paragraph(format_markdown_text(line[2:]), styles[\"Heading1\"])\n",
    "                )\n",
    "            elif line.startswith(\"## \"):\n",
    "                if in_list:\n",
    "                    if list_items:\n",
    "                        elements.append(\n",
    "                            ListFlowable(\n",
    "                                list_items, bulletType=current_list_type or \"bullet\"\n",
    "                            )\n",
    "                        )\n",
    "                        list_items = []\n",
    "                        in_list = False\n",
    "                        current_list_type = None\n",
    "                elements.append(\n",
    "                    Paragraph(format_markdown_text(line[3:]), styles[\"Heading2\"])\n",
    "                )\n",
    "            elif line.startswith(\"### \"):\n",
    "                if in_list:\n",
    "                    if list_items:\n",
    "                        elements.append(\n",
    "                            ListFlowable(\n",
    "                                list_items, bulletType=current_list_type or \"bullet\"\n",
    "                            )\n",
    "                        )\n",
    "                        list_items = []\n",
    "                        in_list = False\n",
    "                        current_list_type = None\n",
    "                elements.append(\n",
    "                    Paragraph(format_markdown_text(line[4:]), styles[\"Heading3\"])\n",
    "                )\n",
    "            elif line.startswith(\"#### \"):\n",
    "                if in_list:\n",
    "                    if list_items:\n",
    "                        elements.append(\n",
    "                            ListFlowable(\n",
    "                                list_items, bulletType=current_list_type or \"bullet\"\n",
    "                            )\n",
    "                        )\n",
    "                        list_items = []\n",
    "                        in_list = False\n",
    "                        current_list_type = None\n",
    "                elements.append(\n",
    "                    Paragraph(format_markdown_text(line[5:]), styles[\"Heading4\"])\n",
    "                )\n",
    "            elif line.startswith(\"##### \"):\n",
    "                if in_list:\n",
    "                    if list_items:\n",
    "                        elements.append(\n",
    "                            ListFlowable(\n",
    "                                list_items, bulletType=current_list_type or \"bullet\"\n",
    "                            )\n",
    "                        )\n",
    "                        list_items = []\n",
    "                        in_list = False\n",
    "                        current_list_type = None\n",
    "                elements.append(\n",
    "                    Paragraph(format_markdown_text(line[6:]), styles[\"Heading5\"])\n",
    "                )\n",
    "\n",
    "            # Traiter les éléments de liste\n",
    "            elif line.strip().startswith(\"* \") or line.strip().startswith(\"- \"):\n",
    "                in_list = True\n",
    "                current_list_type = \"bullet\"\n",
    "                text = line.strip()[2:]\n",
    "\n",
    "                # Vérifier s'il s'agit d'une source\n",
    "                if \"(Source:\" in text:\n",
    "                    parts = text.split(\"(Source:\", 1)\n",
    "                    content_text = format_markdown_text(parts[0].strip())\n",
    "                    source_text = \"(Source:\" + parts[1]\n",
    "                    list_items.append(\n",
    "                        ListItem(Paragraph(content_text, styles[\"ListItem\"]))\n",
    "                    )\n",
    "                    list_items.append(\n",
    "                        ListItem(Paragraph(source_text, styles[\"Source\"]))\n",
    "                    )\n",
    "                else:\n",
    "                    list_items.append(\n",
    "                        ListItem(\n",
    "                            Paragraph(format_markdown_text(text), styles[\"ListItem\"])\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            # Traiter les paragraphes normaux\n",
    "            elif line.strip():\n",
    "                if in_list:\n",
    "                    if list_items:\n",
    "                        elements.append(\n",
    "                            ListFlowable(\n",
    "                                list_items, bulletType=current_list_type or \"bullet\"\n",
    "                            )\n",
    "                        )\n",
    "                        list_items = []\n",
    "                        in_list = False\n",
    "                        current_list_type = None\n",
    "\n",
    "                # Vérifier s'il s'agit d'une source\n",
    "                if \"(Source:\" in line:\n",
    "                    parts = line.split(\"(Source:\", 1)\n",
    "                    content_text = format_markdown_text(parts[0].strip())\n",
    "                    source_text = \"(Source:\" + parts[1]\n",
    "                    if content_text:\n",
    "                        elements.append(Paragraph(content_text, styles[\"Normal\"]))\n",
    "                    elements.append(Paragraph(source_text, styles[\"Source\"]))\n",
    "                else:\n",
    "                    elements.append(\n",
    "                        Paragraph(format_markdown_text(line), styles[\"Normal\"])\n",
    "                    )\n",
    "\n",
    "            # Ajouter un espace pour les lignes vides\n",
    "            elif not line.strip() and not in_list:\n",
    "                elements.append(Spacer(1, 3 * mm))\n",
    "\n",
    "        # Ajouter la dernière liste si elle existe\n",
    "        if in_list and list_items:\n",
    "            elements.append(\n",
    "                ListFlowable(list_items, bulletType=current_list_type or \"bullet\")\n",
    "            )\n",
    "\n",
    "        # Générer le PDF\n",
    "        doc.build(elements)\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la conversion en PDF avec ReportLab: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "json_file = \"/mnt/mydisk/Projects/plu/notebooks/output/gemini_response/Zone_UC2.json\"\n",
    "save_as_markdown(json_file, \"Zone_UC2.md\")\n",
    "save_as_pdf(json_file, \"Zone_UC2.pdf\")\n",
    "print(\"Conversion terminée!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completion of the output\n",
    "\n",
    "Complétion de l'analyse de la zone avec les documents de l'OAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "with open(\"/mnt/mydisk/Projects/plu/config/prompts.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    prompt_oap = json.load(f)[\"prompt_oap\"]\n",
    "\n",
    "with open(\"output/gemini_response/Zone_UC2.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    response_data = json.load(f)\n",
    "\n",
    "# OAP\n",
    "with open(\n",
    "    \"/mnt/mydisk/Projects/plu/data/raw/Grenoble/Carnet de Paysage.json\",\n",
    "    \"r\",\n",
    "    encoding=\"utf-8\",\n",
    ") as f:\n",
    "    data_paysage = json.load(f)\n",
    "\n",
    "with open(\n",
    "    \"/mnt/mydisk/Projects/plu/data/raw/Grenoble/Plan de Prévention du Risque Inondation.json\",\n",
    "    \"r\",\n",
    "    encoding=\"utf-8\",\n",
    ") as f:\n",
    "    data_ppri = json.load(f)\n",
    "\n",
    "image_folder_paysage = (\n",
    "    \"/mnt/mydisk/Projects/plu/data/raw/markdown/Grenoble/Carnet de Paysage/images\"\n",
    ")\n",
    "image_folder_ppri = \"/mnt/mydisk/Projects/plu/data/raw/markdown/Grenoble/Plan de Prévention du Risque Inondation/images\"\n",
    "\n",
    "pattern = r\"!\\[(?P<alt>[^\\]]*)\\]\\((?P<filename>[^)]+)\\)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_paysage = [\n",
    "    f\"page {page['index']}: {page['markdown']}\" for page in data_paysage[\"pages\"]\n",
    "]\n",
    "filtered_ppri = [\n",
    "    f\"page {page['index']}: {page['markdown']}\" for page in data_ppri[\"pages\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_data_s2 = []\n",
    "\n",
    "for page_text in filtered_paysage:\n",
    "    prompt_data_s2 += text_to_part_with_images(\n",
    "        text=page_text,\n",
    "        pattern=pattern,\n",
    "        image_folder=image_folder_paysage,\n",
    "    )\n",
    "\n",
    "for page_text in filtered_ppri:\n",
    "    prompt_data_s2 += text_to_part_with_images(\n",
    "        text=page_text,\n",
    "        pattern=pattern,\n",
    "        image_folder=image_folder_ppri,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_oap(\n",
    "    zone: str,\n",
    "    prompt: str,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Récupère le prompt pour la ville de Grenoble.\n",
    "\n",
    "    Args:\n",
    "        data_general: (dict) Les données générales de la ville de Grenoble.\n",
    "        data_par_zone: (dict) Les données par zone de la ville de Grenoble.\n",
    "        data_zone: (dict) Les données de zone de la ville de Grenoble.\n",
    "        type_zone: (str) Le type de zone à analyser.\n",
    "        zone: (str) La zone à analyser.\n",
    "        prompt: (str) Le prompt de base.\n",
    "\n",
    "    Returns:\n",
    "        str: Le prompt pour la ville de Grenoble.\n",
    "    \"\"\"\n",
    "    return prompt.format(\n",
    "        ANALYSE_PRELIMINAIRE_A_PEAUFINER=\"ANALYSE_PRELIMINAIRE_A_PEAUFINER\",\n",
    "        NOUVEAUX_DOCUMENTS_OAP=\"NOUVEAUX_DOCUMENTS_OAP\",\n",
    "        ZONE_CADASTRALE_CIBLE=zone,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_oap = get_prompt_oap(\n",
    "    zone=\"Zone UC2\",\n",
    "    prompt=prompt_oap,\n",
    ").split(\"NOUVEAUX_DOCUMENTS_OAP\")\n",
    "prompt_final_oap = (\n",
    "    [types.Part.from_text(text=prompt_template_oap[0].split(\"ANALYSE_PRELIMINAIRE_A_PEAUFINER\")[0])]\n",
    "    + [types.Part.from_text(text=response_data[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"])]\n",
    "    + [types.Part.from_text(text=prompt_template_oap[0].split(\"ANALYSE_PRELIMINAIRE_A_PEAUFINER\")[1])]\n",
    "    + prompt_data_s2\n",
    "    + [types.Part.from_text(text=prompt_template_oap[1])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(\n",
    "    api_key=os.environ.get(\"GOOGLE_AI_API_KEY\"),\n",
    ")\n",
    "model = \"gemini-2.5-pro-exp-03-25\"\n",
    "generate_content_config = types.GenerateContentConfig(\n",
    "    response_mime_type=\"text/plain\",\n",
    ")\n",
    "response = client.models.generate_content(\n",
    "    model=model,\n",
    "    contents=prompt_final_oap,\n",
    "    config=generate_content_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json_data(\n",
    "    data=response.to_json_dict(), file_path=Path(\"output/gemini_response/Zone_UC2_et_oap.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.platypus import (\n",
    "    SimpleDocTemplate,\n",
    "    Paragraph,\n",
    "    Spacer,\n",
    "    ListItem,\n",
    "    ListFlowable,\n",
    "    Table,\n",
    "    TableStyle,\n",
    ")\n",
    "from reportlab.lib.units import mm\n",
    "\n",
    "\n",
    "def extract_text_from_json(json_file_path):\n",
    "    \"\"\"\n",
    "    Extrait le contenu textuel de la réponse du modèle à partir du fichier JSON.\n",
    "\n",
    "    Args:\n",
    "        json_file_path (str): Chemin vers le fichier JSON\n",
    "\n",
    "    Returns:\n",
    "        str: Le contenu textuel extrait\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ouvrir et charger le fichier JSON\n",
    "        with open(json_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        # Naviguer dans la structure JSON pour obtenir le texte\n",
    "        # Vérifier la structure pour s'assurer que tous les champs existent\n",
    "        if (\n",
    "            \"candidates\" in data\n",
    "            and len(data[\"candidates\"]) > 0\n",
    "            and \"content\" in data[\"candidates\"][0]\n",
    "            and \"parts\" in data[\"candidates\"][0][\"content\"]\n",
    "            and len(data[\"candidates\"][0][\"content\"][\"parts\"]) > 0\n",
    "            and \"text\" in data[\"candidates\"][0][\"content\"][\"parts\"][0]\n",
    "        ):\n",
    "            # Extraire le texte\n",
    "            text_content = data[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "\n",
    "            # Extraire le contenu Markdown en supprimant les balises de code\n",
    "            if text_content.startswith(\"```\") and \"```\" in text_content:\n",
    "                # Utiliser une expression régulière pour extraire le contenu entre les balises de code\n",
    "                match = re.search(r\"```(?:text|markdown)?\\n([\\s\\S]*?)```\", text_content)\n",
    "                if match:\n",
    "                    return match.group(1)\n",
    "\n",
    "            return text_content\n",
    "        else:\n",
    "            return \"Structure JSON invalide. Impossible de trouver le contenu textuel.\"\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        return \"Le fichier n'est pas un JSON valide.\"\n",
    "    except Exception as e:\n",
    "        return f\"Une erreur est survenue: {str(e)}\"\n",
    "\n",
    "\n",
    "def save_as_markdown(json_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    Extrait le contenu du JSON et le sauvegarde en format Markdown.\n",
    "\n",
    "    Args:\n",
    "        json_file_path (str): Chemin vers le fichier JSON\n",
    "        output_file_path (str): Chemin où sauvegarder le fichier Markdown\n",
    "\n",
    "    Returns:\n",
    "        bool: True si l'opération a réussi, False sinon\n",
    "    \"\"\"\n",
    "    try:\n",
    "        content = extract_text_from_json(json_file_path)\n",
    "\n",
    "        # Sauvegarder dans un fichier Markdown\n",
    "        with open(output_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(content)\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la sauvegarde en Markdown: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def format_markdown_text(text):\n",
    "    \"\"\"\n",
    "    Convertit certaines balises Markdown en balises HTML pour ReportLab.\n",
    "\n",
    "    Args:\n",
    "        text (str): Texte avec formatage Markdown\n",
    "\n",
    "    Returns:\n",
    "        str: Texte avec balises HTML\n",
    "    \"\"\"\n",
    "    # Convertir le texte en gras (**texte**) en balises HTML <b>\n",
    "    text = re.sub(r\"\\*\\*(.*?)\\*\\*\", r\"<b>\\1</b>\", text)\n",
    "\n",
    "    # Convertir le texte en italique (*texte*) en balises HTML <i>\n",
    "    text = re.sub(r\"(?<!\\*)\\*(?!\\*)(.*?)(?<!\\*)\\*(?!\\*)\", r\"<i>\\1</i>\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def save_as_pdf(json_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    Extrait le contenu du JSON et le sauvegarde en format PDF en utilisant ReportLab.\n",
    "\n",
    "    Args:\n",
    "        json_file_path (str): Chemin vers le fichier JSON\n",
    "        output_file_path (str): Chemin où sauvegarder le fichier PDF\n",
    "\n",
    "    Returns:\n",
    "        bool: True si l'opération a réussi, False sinon\n",
    "    \"\"\"\n",
    "    try:\n",
    "        content = extract_text_from_json(json_file_path)\n",
    "\n",
    "        # Créer un nouveau document PDF\n",
    "        doc = SimpleDocTemplate(\n",
    "            output_file_path,\n",
    "            pagesize=A4,\n",
    "            rightMargin=20 * mm,\n",
    "            leftMargin=20 * mm,\n",
    "            topMargin=20 * mm,\n",
    "            bottomMargin=20 * mm,\n",
    "        )\n",
    "\n",
    "        # Définir les styles\n",
    "        styles = getSampleStyleSheet()\n",
    "\n",
    "        # Modifier les styles existants au lieu d'en ajouter de nouveaux\n",
    "        styles[\"Heading1\"].fontSize = 16\n",
    "        styles[\"Heading1\"].spaceAfter = 10\n",
    "        styles[\"Heading1\"].spaceBefore = 20\n",
    "        styles[\"Heading1\"].textColor = colors.darkblue\n",
    "\n",
    "        styles[\"Heading2\"].fontSize = 14\n",
    "        styles[\"Heading2\"].spaceAfter = 8\n",
    "        styles[\"Heading2\"].spaceBefore = 16\n",
    "        styles[\"Heading2\"].textColor = colors.darkblue\n",
    "\n",
    "        styles[\"Heading3\"].fontSize = 12\n",
    "        styles[\"Heading3\"].spaceAfter = 6\n",
    "        styles[\"Heading3\"].spaceBefore = 12\n",
    "        styles[\"Heading3\"].textColor = colors.darkblue\n",
    "\n",
    "        # Vérifier si Heading4 existe et le modifier ou le créer\n",
    "        if \"Heading4\" in styles:\n",
    "            styles[\"Heading4\"].fontSize = 11\n",
    "            styles[\"Heading4\"].spaceAfter = 4\n",
    "            styles[\"Heading4\"].spaceBefore = 10\n",
    "            styles[\"Heading4\"].textColor = colors.darkblue\n",
    "        else:\n",
    "            styles.add(\n",
    "                ParagraphStyle(\n",
    "                    name=\"Heading4\",\n",
    "                    parent=styles[\"Normal\"],\n",
    "                    fontSize=11,\n",
    "                    spaceAfter=4,\n",
    "                    spaceBefore=10,\n",
    "                    textColor=colors.darkblue,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Vérifier si Heading5 existe et le modifier ou le créer\n",
    "        if \"Heading5\" in styles:\n",
    "            styles[\"Heading5\"].fontSize = 10\n",
    "            styles[\"Heading5\"].spaceAfter = 4\n",
    "            styles[\"Heading5\"].spaceBefore = 8\n",
    "            styles[\"Heading5\"].textColor = colors.darkblue\n",
    "        else:\n",
    "            styles.add(\n",
    "                ParagraphStyle(\n",
    "                    name=\"Heading5\",\n",
    "                    parent=styles[\"Normal\"],\n",
    "                    fontSize=10,\n",
    "                    spaceAfter=4,\n",
    "                    spaceBefore=8,\n",
    "                    textColor=colors.darkblue,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Modifier le style Normal\n",
    "        styles[\"Normal\"].fontSize = 10\n",
    "        styles[\"Normal\"].spaceAfter = 6\n",
    "\n",
    "        # Vérifier si ListItem existe et le modifier ou le créer\n",
    "        if \"ListItem\" in styles:\n",
    "            styles[\"ListItem\"].leftIndent = 20\n",
    "            styles[\"ListItem\"].spaceAfter = 3\n",
    "        else:\n",
    "            styles.add(\n",
    "                ParagraphStyle(\n",
    "                    name=\"ListItem\",\n",
    "                    parent=styles[\"Normal\"],\n",
    "                    leftIndent=20,\n",
    "                    spaceAfter=3,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Créer le style Source (il n'existe pas par défaut)\n",
    "        styles.add(\n",
    "            ParagraphStyle(\n",
    "                name=\"Source\",\n",
    "                parent=styles[\"Normal\"],\n",
    "                fontSize=8,\n",
    "                textColor=colors.grey,\n",
    "                spaceAfter=6,\n",
    "                leftIndent=20,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Préparer la liste des éléments à ajouter au PDF\n",
    "        elements = []\n",
    "\n",
    "        # Traiter le contenu ligne par ligne\n",
    "        lines = content.split(\"\\n\")\n",
    "        in_list = False\n",
    "        list_items = []\n",
    "        current_list_type = None  # 'bullet' ou 'numbered'\n",
    "\n",
    "        for line in lines:\n",
    "            # Traiter les en-têtes\n",
    "            if line.startswith(\"# \"):\n",
    "                if in_list:\n",
    "                    # Ajouter la liste précédente si on entre dans un nouvel élément\n",
    "                    if list_items:\n",
    "                        elements.append(\n",
    "                            ListFlowable(\n",
    "                                list_items, bulletType=current_list_type or \"bullet\"\n",
    "                            )\n",
    "                        )\n",
    "                        list_items = []\n",
    "                        in_list = False\n",
    "                        current_list_type = None\n",
    "                elements.append(\n",
    "                    Paragraph(format_markdown_text(line[2:]), styles[\"Heading1\"])\n",
    "                )\n",
    "            elif line.startswith(\"## \"):\n",
    "                if in_list:\n",
    "                    if list_items:\n",
    "                        elements.append(\n",
    "                            ListFlowable(\n",
    "                                list_items, bulletType=current_list_type or \"bullet\"\n",
    "                            )\n",
    "                        )\n",
    "                        list_items = []\n",
    "                        in_list = False\n",
    "                        current_list_type = None\n",
    "                elements.append(\n",
    "                    Paragraph(format_markdown_text(line[3:]), styles[\"Heading2\"])\n",
    "                )\n",
    "            elif line.startswith(\"### \"):\n",
    "                if in_list:\n",
    "                    if list_items:\n",
    "                        elements.append(\n",
    "                            ListFlowable(\n",
    "                                list_items, bulletType=current_list_type or \"bullet\"\n",
    "                            )\n",
    "                        )\n",
    "                        list_items = []\n",
    "                        in_list = False\n",
    "                        current_list_type = None\n",
    "                elements.append(\n",
    "                    Paragraph(format_markdown_text(line[4:]), styles[\"Heading3\"])\n",
    "                )\n",
    "            elif line.startswith(\"#### \"):\n",
    "                if in_list:\n",
    "                    if list_items:\n",
    "                        elements.append(\n",
    "                            ListFlowable(\n",
    "                                list_items, bulletType=current_list_type or \"bullet\"\n",
    "                            )\n",
    "                        )\n",
    "                        list_items = []\n",
    "                        in_list = False\n",
    "                        current_list_type = None\n",
    "                elements.append(\n",
    "                    Paragraph(format_markdown_text(line[5:]), styles[\"Heading4\"])\n",
    "                )\n",
    "            elif line.startswith(\"##### \"):\n",
    "                if in_list:\n",
    "                    if list_items:\n",
    "                        elements.append(\n",
    "                            ListFlowable(\n",
    "                                list_items, bulletType=current_list_type or \"bullet\"\n",
    "                            )\n",
    "                        )\n",
    "                        list_items = []\n",
    "                        in_list = False\n",
    "                        current_list_type = None\n",
    "                elements.append(\n",
    "                    Paragraph(format_markdown_text(line[6:]), styles[\"Heading5\"])\n",
    "                )\n",
    "\n",
    "            # Traiter les éléments de liste\n",
    "            elif line.strip().startswith(\"* \") or line.strip().startswith(\"- \"):\n",
    "                in_list = True\n",
    "                current_list_type = \"bullet\"\n",
    "                text = line.strip()[2:]\n",
    "\n",
    "                # Vérifier s'il s'agit d'une source\n",
    "                if \"(Source:\" in text:\n",
    "                    parts = text.split(\"(Source:\", 1)\n",
    "                    content_text = format_markdown_text(parts[0].strip())\n",
    "                    source_text = \"(Source:\" + parts[1]\n",
    "                    list_items.append(\n",
    "                        ListItem(Paragraph(content_text, styles[\"ListItem\"]))\n",
    "                    )\n",
    "                    list_items.append(\n",
    "                        ListItem(Paragraph(source_text, styles[\"Source\"]))\n",
    "                    )\n",
    "                else:\n",
    "                    list_items.append(\n",
    "                        ListItem(\n",
    "                            Paragraph(format_markdown_text(text), styles[\"ListItem\"])\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            # Traiter les paragraphes normaux\n",
    "            elif line.strip():\n",
    "                if in_list:\n",
    "                    if list_items:\n",
    "                        elements.append(\n",
    "                            ListFlowable(\n",
    "                                list_items, bulletType=current_list_type or \"bullet\"\n",
    "                            )\n",
    "                        )\n",
    "                        list_items = []\n",
    "                        in_list = False\n",
    "                        current_list_type = None\n",
    "\n",
    "                # Vérifier s'il s'agit d'une source\n",
    "                if \"(Source:\" in line:\n",
    "                    parts = line.split(\"(Source:\", 1)\n",
    "                    content_text = format_markdown_text(parts[0].strip())\n",
    "                    source_text = \"(Source:\" + parts[1]\n",
    "                    if content_text:\n",
    "                        elements.append(Paragraph(content_text, styles[\"Normal\"]))\n",
    "                    elements.append(Paragraph(source_text, styles[\"Source\"]))\n",
    "                else:\n",
    "                    elements.append(\n",
    "                        Paragraph(format_markdown_text(line), styles[\"Normal\"])\n",
    "                    )\n",
    "\n",
    "            # Ajouter un espace pour les lignes vides\n",
    "            elif not line.strip() and not in_list:\n",
    "                elements.append(Spacer(1, 3 * mm))\n",
    "\n",
    "        # Ajouter la dernière liste si elle existe\n",
    "        if in_list and list_items:\n",
    "            elements.append(\n",
    "                ListFlowable(list_items, bulletType=current_list_type or \"bullet\")\n",
    "            )\n",
    "\n",
    "        # Générer le PDF\n",
    "        doc.build(elements)\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la conversion en PDF avec ReportLab: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "json_file = \"/mnt/mydisk/Projects/plu/notebooks/output/gemini_response/Zone_UC2_et_oap.json\"\n",
    "save_as_markdown(json_file, \"Zone_UC2_et_oap.md\")\n",
    "save_as_pdf(json_file, \"Zone_UC2_et_oap.pdf\")\n",
    "print(\"Conversion terminée!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
